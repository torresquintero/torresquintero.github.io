<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Ale Torresquintero</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<meta name="author" content="" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">

	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
	<div id="colorlib-page">
		<div class="container-wrap">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
			<div class="text-center">
				<div class="author-img" style="background-image: url(images/about.jpg);"></div>
				<h1 id="colorlib-logo"><a href="index.html">Ale Torresquintero</a></h1>
				<span class="position"><a href="https://en.wikipedia.org/wiki/Speech_synthesis">AI voice nerd</a> ü§ì in London</span>
			</div>
			<nav id="colorlib-main-menu" role="navigation" class="navbar">
				<div id="navbar" class="collapse">
					<ul>
						<li class="active"><a href="#" data-nav-section="home">Home</a></li>
						<li><a href="#" data-nav-section="about">About</a></li>
						<li><a href="#" data-nav-section="blog">Blog</a></li>
						<li><a href="#" data-nav-section="publications">Publications</a></li>
						<li><a href="#" data-nav-section="education">Education</a></li>
					</ul>
				</div>
			</nav>

			<br/><br/><br/>
			<div class="colorlib-footer">
				<p><small>&copy; <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright <script>document.write(new Date().getFullYear());</script> All rights reserved. Made with <i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --> </span> <span>Distributed by <a href="https://themewagon.com/themes/free-bootstrap-portfolio-website-template/" target="_blank">ThemeWagon</a></span></small></p>
				<ul>
					<li><a href="#"><i class="icon-facebook2"></i></a></li>
					<li><a href="#"><i class="icon-twitter2"></i></a></li>
					<li><a href="#"><i class="icon-instagram"></i></a></li>
					<li><a href="#"><i class="icon-linkedin2"></i></a></li>
				</ul>
			</div>

		</aside>

		<div id="colorlib-main">
			<section data-section="home" class="js-fullheight" id="home">

				<div id="colorlib-counter" class="colorlib-counters" style="background-image: url(images/img_bg_2.jpg);" data-stellar-background-ratio="0.5">
					<div class="overlay"></div>
					<div class="colorlib-narrow-content" id="home-narrow-content">
						<div class="row">
							<div class="col-md-4 text-center animate-box">
								<span class="colorlib-counter">CV</span>
								<a class="btn btn-primary btn-learn" href="files/Ale_Torresquintero_CV.pdf" download="Ale_Torresquintero_CV.pdf">Download CV <i class="icon-download4"></i></a>
							</div>
							<div class="col-md-4 text-center animate-box">
								<span class="colorlib-counter">LinkedIn</span>
								<a class="btn btn-primary btn-learn" href="https://www.linkedin.com/in/alexandra-torresquintero/" download="Ale_Torresquintero_CV.pdf">Visit LinkedIn <i class="icon-linkedin2"></i></a>
							</div>
							<div class="col-md-4 text-center animate-box">
								<span class="colorlib-counter">GitHub</span>
								<a class="btn btn-primary btn-learn" href="https://github.com/torresquintero" download="Ale_Torresquintero_CV.pdf">Visit GitHub <i class="icon-github"></i></a>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section class="colorlib-about" data-section="about">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<h2 class="colorlib-heading">About</h2>
										<p>I discovered linguistics in my first year at Yale, and instantly fell in love with speech. That something so intuitive and easy for
											humans to use and understand could be equally as difficult for computers to process enthralled me. This discrepancy only
											reinforced itself when I was on the Google Assistant team. WaveNet was deployed to production alongside the first US-english
											male voice, which I helped record the training data for, but no one on my team could explain to me how WaveNet worked.
											Frustrated by this, I applied (and got accepted to!) Edinburgh's Speech and Language Processing programme, where I not
											only learned exactly how WaveNet worked, but actually got to manually construct it (from scratch) for my masters dissertation.</p>
										<p>But I couldn't get enough of speech synthesis, and subsequently started a data engineering role at Papercup, a small
											15-person AI dubbing startup, proclaiming that I'd take any job as long as I got to do something with speech synthesis. As
											Papercup grew, so did my interests. After almost three years I transitioned to a machine learning language engineer role,
											getting to do more experimentation and research, and owning the training and deployment of new voices to the product. After
											over 4 years at Papercup, we had almost 70 employees, and even more custom deployed voices, and it was time for me to
											take a long-needed break. But I'm eagerly looking forward to stretching my machine learning and research brain in my next
											opportunity!</p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section id="blog" class="colorlib-blog" data-section="blog">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading">Blog</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="blogposts/interspeech2022-tts-overview.html" class="blog-img">
                                    <img src="images/trantra-incheon.jpg" class="img-responsive" alt="HTML5 Bootstrap Template by colorlib.com">
                                </a>
								<div class="desc">
									<span><small>2 December 2022</small></span>
									<h3><a href="blogposts/interspeech2022-tts-overview.html">Overview of TTS at Interspeech 2022</a></h3>
									<p>We hope you enjoyed our first blog post about our highlights of Interspeech 2022.
                                         Here we'd like to cover the topics nearest and dearest to our ...</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<div class="blog-entry">
								<a href="blogposts/interspeech2022-highlights.html" class="blog-img">
                                    <img src="images/archway.jpg" class="img-responsive" alt="HTML5 Bootstrap Template by colorlib.com">
                                </a>
								<div class="desc">
									<span><small>26 October 2022</small></span>
									<h3><a href="blogposts/interspeech2022-highlights.html">Highlights of Interspeech 2022</a></h3>
									<p>This year Interspeech was hosted in Korea. It was our first time visiting this
                                        beautiful country and we can't wait to go back again! We had ... </p>
								</div>
							</div>
						</div>
						<div class="col-md-4 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							<div class="blog-entry">
								<a href="blogposts/uk-speech-2022.html" class="blog-img">
                                    <img src="images/team.jpg" class="img-responsive" alt="HTML5 Bootstrap Template by colorlib.com">
                                </a>
								<div class="desc">
									<span><small>14 October 2022</small></span>
									<h3><a href="blogposts/uk-speech-2022.html">üêª Papercubs go to UK Speech 2022</a></h3>
									<p>For the first in-person UK Speech Conference in 3 years, we were lucky enough
                                        to be able to attend with most of our machine learning team as ... </p>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12 animate-box">
							<p><a href="blog.html" class="btn btn-primary btn-lg btn-load-more">Load more <i class="icon-reload"></i></a></p>
						</div>
					</div>
				</div>
			</section>


			<section class="colorlib-publications" data-section="publications">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box" data-animate-effect="fadeInLeft">
								<div class="col-md-12">
									<div class="about-desc">
										<h2 class="colorlib-heading">Publications</h2>
									</div>
								</div>
							</div>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							UK Speech 2023
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p><strong>Torresquintero, A.</strong>, G√≥mez Ibarrondo, T., Wallis, C. G. R., Hu, V., Leoni, J., Ram Mohan, D. S., Hodari, Z.
								(2023). Incremental Training Changes to Improve Synthesis Quality. UK Speech 2023, Sheffield, UK. (pp.
								109). Link: <a href="https://drive.google.com/file/d/1qv5Q1vwZUA_tGsIz63wND7k2WwOhEKgJ/view">Google Drive</a></p>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							ICASSP 2023
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p>Teh, T. H., Hu, V., Ram Mohan, D. S., Hodari, Z., Wallis, C. G. R., G√≥mez Ibarrondo, T., <strong>Torresquintero, A.</strong>,
								Leoni, J., Gales, M., King, S. (2023). Ensemble Prosody Prediction For Expressive Speech Synthesis. In
								Proc. ICASSP 2023. doi: <a href="https://doi.org/10.1109/ICASSP49357.2023.10096962">10.1109/ICASSP49357.2023.10096962</a></p>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							Interspeech 2021
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p><strong>Torresquintero, A.</strong>, Teh, T. H., Wallis, C. G. R., Staib, M., Ram Mohan, D. S., Hu, V., Foglianti, L., Gao, J., &
								King, S. (2021). ADEPT: A Dataset for Evaluating Prosody Transfer. In Proc. Interspeech 2021 (pp.
								3880-3884). doi: <a href="https://doi.org/10.21437/Interspeech.2021-1610">10.21437/Interspeech.2021-1610</a></p>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							Interspeech 2021
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p>Mohan, D. S. R., Hu, V., Teh, T. H., <strong>Torresquintero, A.</strong>, Wallis, C. G. R., Staib, M., Foglianti, L., Gao, J., &
								King, S. (2021). Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis. In Proc. Interspeech
								2021 (pp. 3875-3879). doi: <a href="https://doi.org/10.21437/Interspeech.2021-1583">10.21437/Interspeech.2021-1583</a></p>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							Interspeech 2020
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p>Staib, M., Teh, T. H., <strong>Torresquintero, A.</strong>, Mohan, D. S. R., Foglianti, L., Lenain, R., & Gao, J. (2020).
								Phonological Features for 0-Shot Multilingual Speech Synthesis. In Proc. Interspeech 2020 (pp. 2942-2946).
								doi: <a href="https://doi.org/10.21437/Interspeech.2020-1821">10.21437/Interspeech.2020-1821</a></p>
						</div>
					</div>
					<div class="row">
						<div class="col-md-3 col-sm-6 animate-box" data-animate-effect="fadeInLeft">
							Interspeech 2020
						</div>
						<div class="col-md-9 col-sm-6 animate-box" data-animate-effect="fadeInRight">
							<p>Mohan, D.S.R., Lenain, R., Foglianti, L., Teh, T.H., Staib, M., <strong>Torresquintero, A.</strong>, Gao, J. (2021).
								Incremental Text to Speech for Neural Sequence-to-Sequence Models Using Reinforcement Learning. In Proc. Interspeech 2021 (pp.
								3880-3884). doi: <a href="https://doi.org/10.21437/Interspeech.2020-1822">10.21437/Interspeech.2020-1822</a></p>
						</div>
					</div>
				</div>
			</section>


			<section class="colorlib-education" data-section="education">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading animate-box">Education</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12 animate-box" data-animate-effect="fadeInLeft">
							<div class="fancy-collapse-panel">
								<div class="panel-group" id="accordion" role="tablist" aria-multiselectable="true">
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingOne">
									        <h4 class="panel-title">
									            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
													Master of Science in Speech and Language Processing <br/><br/>
													University of Edinburgh | 2018 - 2019 | Edinburgh, UK
									            </a>
									        </h4>
									    </div>
									    <div id="collapseOne" class="panel-collapse collapse in" role="tabpanel" aria-labelledby="headingOne">
									         <div class="panel-body">
									            <div class="row">
										      		<div class="col-md-12">
														<div>76% average (Distinction) in courses. Selected coursework:
														<ul>
															<li>Compared monophone and triphone HMM-GMM models and HMM-DNN models for ASR using Kaldi.</li>
															<li>Built a unit selection speech synthesiser using Festival, with recordings from own voice.</li>
															<li>Implemented multiple methods to compute similarity between sparse word vectors from a Twitter Corpus.</li>
															<li>Built a diphonic speech synthesiser in Python from scratch.</li>
															<li>Created an ASR digit recogniser using the HTK and Bash.</li>
															<li>Implemented an RNN to model English verb agreement.</li>
															<li>Experimented with attention-based LSTM network depths and the inclusion or exclusion of a lexical model to an encoder-decoder framework for MT from Japanese to English.</li>
														</ul>
														</div>
														<div>70% (Distinction) on dissertation
														<ul><li>Manually created (from scratch) an implementation of the WaveNet audio generative model in PyTorch.</li></ul>
														</div>
													</div>
										      	</div>
									         </div>
									    </div>
									</div>
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingTwo">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
													Bachelor's in Linguistics<br/><br/>
													Yale University | 2012 - 2016 | New Haven, CT, USA
									            </a>
									        </h4>
									    </div>
									    <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
									        <div class="panel-body">
												<div>Courses in phonetics, phonology, computational linguistics, syntax, morphology, and computer science.<br/>
													Senior thesis research on stress in American English.<br>
													Scholarship awards:
													<ul>
														<li>Sterling Scholar</li>
														<li>M. Albert Geib Scholar</li>
													</ul>
												</div>
									        </div>
									    </div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

		</div><!-- end:colorlib-main -->
	</div><!-- end:container-wrap -->
	</div><!-- end:colorlib-page -->

	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>


	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

